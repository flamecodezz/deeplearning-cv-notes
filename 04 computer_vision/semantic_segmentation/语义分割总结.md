



``` 
- 什么是超像素、语义分割、实例分割、全景分割？
- 什么是同物异谱、同谱异物？
- RGB图像、全色图像、多光谱图像、高光谱图像？
- ...
- 语义分割发展和历史
	- 2000年之前，数字图像处理时我们采用方法基于几类：阈值分割、区域分割、边缘分割、纹理特征、聚类等
	- 2000年到2010年期间， 主要方法有四类：基于图论、聚类、分类以及聚类和分类结合。
	- 2010年至今，神经网络模型的崛起和深度学习的发展，主要涉及到几种模型
	发展历程：
		- 2014年 FCN 模型，主要贡献为在语义分割问题中推广使用端对端卷积神经网络，使用反卷积进行上采样
		- 2015年 U-net 模型，构建了一套完整 的编码解码器
		- 2015年 SegNet 模型，将最大池化转换为解码器来提高分辨率
		- 2015年 Dilated Convolutions（空洞卷积），更广范围内提高了内容的聚合并不降低分辨率
		- 2016年 DeepLab v1&v2
		- 2016年 RefineNet 使用残差连接，降低了内存使用量，提高了模块间的特征融合
		- 2016年 PSPNet 模型
		- 2017年 Large Kernel Matters
		- 2017年 DeepLab V3
		以上几种模型可以按照语义分割模型的独有方法进行分类，如专门池化（PSPNet、DeepLab），编码器-解码器架构（SegNet、E-Net），多尺度处理（DeepLab）、条件随机场（CRFRNN）、空洞卷积（DiatedNet、DeepLab）和跳跃连接（FCN）。
		
- 前DL时代的语义分割： 
	- Grab cut是微软剑桥研究院于2004年提出的著名交互式图像语义分割方法。与N-cut一样，grab cut同样也是基于图划分，不过grab cut是其改进版本，可以看作迭代式的语义分割算法。Grab cut利用了图像中的纹理（颜色）信息和边界（反差）信息，只要少量的用户交互操作即可得到比较好的前后背景分割结果。
	。。。
- DL时代
```





``` 
语义分割是对图像的一种更精细的推断与理解，由粗到细为：

- 图像分类 - 初级的图片理解，其对整张图片进行整体理解.
- 目标定位与检测 - 不仅提供图像内的类别，还包括相对于物体类别的空间为位置信息.
- 语义分割 - 对每个图像像素进行密集预测，得到像素类别信息.

图像的语义分割是将输入图像中的每个像素分配一个语义类别，以得到像素化的密集分类。

虽然自 2007 年以来，语义分割/场景解析一直是计算机视觉社区的一部分，但与计算机视觉中的其他领域很相似，自 2014 年 Long 等人首次使用全卷积神经网络对自然图像进行端到端分割，语义分割才有了重大突破。

——from：https://www.aiuai.cn/aifarm602.html#E-Net%E5%92%8CLink-Net
```

